import sys
_module = sys.modules[__name__]
del sys
conf = _module
integration_tests = _module
__main__ = _module
experiment = _module
object_detection_tests = _module
semantic_segmentation_tests = _module
util = _module
flip_scene = _module
generate_scene = _module
misc = _module
integration_tests2 = _module
config = _module
object_detection = _module
semantic_segmentation = _module
rastervision = _module
analyzer = _module
analyzer_config = _module
api = _module
stats_analyzer = _module
stats_analyzer_config = _module
augmentor = _module
augmentor_config = _module
nodata_augmentor = _module
nodata_augmentor_config = _module
backend = _module
backend_config = _module
keras_classification = _module
builders = _module
model_builder = _module
optimizer_builder = _module
trainer_builder = _module
commands = _module
train = _module
core = _module
trainer = _module
models = _module
resnet50 = _module
utils = _module
keras_classification_config = _module
pytorch_chip_classification = _module
pytorch_chip_classification_config = _module
pytorch_object_detection = _module
pytorch_object_detection_config = _module
pytorch_semantic_segmentation = _module
pytorch_semantic_segmentation_config = _module
simple_backend_config = _module
tf_deeplab = _module
tf_deeplab_config = _module
tf_object_detection = _module
tf_object_detection_config = _module
torch_utils = _module
chip_classification = _module
data = _module
folder = _module
model = _module
plot = _module
metrics = _module
boxlist = _module
data = _module
model = _module
cli = _module
main = _module
verbosity = _module
command = _module
analyze_command = _module
analyze_command_config = _module
aux = _module
cogify_command = _module
aux_command = _module
aux_command_config = _module
bundle_command = _module
bundle_command_config = _module
chip_command = _module
chip_command_config = _module
command_config = _module
eval_command = _module
eval_command_config = _module
predict_command = _module
predict_command_config = _module
train_command = _module
train_command_config = _module
box = _module
class_map = _module
command_io_definition = _module
raster_stats = _module
training_data = _module
activate_mixin = _module
crs_transformer = _module
identity_crs_transformer = _module
rasterio_crs_transformer = _module
dataset = _module
dataset_config = _module
label = _module
chip_classification_labels = _module
labels = _module
object_detection_labels = _module
semantic_segmentation_labels = _module
tfod_utils = _module
np_box_list = _module
np_box_list_ops = _module
np_box_ops = _module
label_source = _module
chip_classification_label_source = _module
chip_classification_label_source_config = _module
default = _module
label_source_config = _module
object_detection_label_source = _module
object_detection_label_source_config = _module
segmentation_class_transformer = _module
semantic_segmentation_label_source = _module
semantic_segmentation_label_source_config = _module
label_store = _module
chip_classification_geojson_store = _module
chip_classification_geojson_store_config = _module
label_store_config = _module
object_detection_geojson_store = _module
object_detection_geojson_store_config = _module
semantic_segmentation_raster_store = _module
semantic_segmentation_raster_store_config = _module
raster_source = _module
raster_source_config = _module
rasterio_source = _module
rasterio_source_config = _module
rasterized_source = _module
rasterized_source_config = _module
raster_transformer = _module
noop_transformer = _module
raster_transformer_config = _module
stats_transformer = _module
stats_transformer_config = _module
scene = _module
scene_config = _module
vector_source = _module
class_inference = _module
geojson_vector_source = _module
geojson_vector_source_config = _module
label_maker = _module
filter = _module
vector_source_config = _module
vector_tile_vector_source = _module
vector_tile_vector_source_config = _module
evaluation = _module
chip_classification_evaluation = _module
chip_classification_evaluator = _module
chip_classification_evaluator_config = _module
class_evaluation_item = _module
classification_evaluation = _module
classification_evaluator = _module
classification_evaluator_config = _module
evaluation_item = _module
evaluator = _module
evaluator_config = _module
object_detection_evaluation = _module
object_detection_evaluator = _module
object_detection_evaluator_config = _module
semantic_segmentation_evaluation = _module
semantic_segmentation_evaluator = _module
semantic_segmentation_evaluator_config = _module
experiment_config = _module
experiment_loader = _module
experiment_set = _module
filesystem = _module
http_filesystem = _module
local_filesystem = _module
s3_filesystem = _module
plugin = _module
predictor = _module
protos = _module
analyzer_pb2 = _module
augmentor_pb2 = _module
backend_pb2 = _module
class_item_pb2 = _module
command_pb2 = _module
dataset_pb2 = _module
deeplab = _module
train_pb2 = _module
evaluator_pb2 = _module
experiment_pb2 = _module
model_pb2 = _module
optimizer_pb2 = _module
pipeline_pb2 = _module
trainer_pb2 = _module
label_source_pb2 = _module
label_store_pb2 = _module
plugin_pb2 = _module
raster_source_pb2 = _module
raster_transformer_pb2 = _module
scene_pb2 = _module
task_pb2 = _module
anchor_generator_pb2 = _module
argmax_matcher_pb2 = _module
bipartite_matcher_pb2 = _module
box_coder_pb2 = _module
box_predictor_pb2 = _module
eval_pb2 = _module
faster_rcnn_box_coder_pb2 = _module
faster_rcnn_pb2 = _module
graph_rewriter_pb2 = _module
grid_anchor_generator_pb2 = _module
hyperparams_pb2 = _module
image_resizer_pb2 = _module
input_reader_pb2 = _module
keypoint_box_coder_pb2 = _module
losses_pb2 = _module
matcher_pb2 = _module
mean_stddev_box_coder_pb2 = _module
multiscale_anchor_generator_pb2 = _module
post_processing_pb2 = _module
preprocessor_pb2 = _module
region_similarity_calculator_pb2 = _module
square_box_coder_pb2 = _module
ssd_anchor_generator_pb2 = _module
ssd_pb2 = _module
string_int_label_map_pb2 = _module
vector_source_pb2 = _module
registry = _module
runner = _module
aws_batch_experiment_runner = _module
command_dag = _module
command_definition = _module
command_runner = _module
experiment_runner = _module
inprocess_experiment_runner = _module
local_experiment_runner = _module
out_of_process_experiment_runner = _module
rv_config = _module
task = _module
chip_classification_config = _module
object_detection_config = _module
semantic_segmentation_config = _module
task_config = _module
files = _module
filter_geojson = _module
zxy2geotiff = _module
version = _module
aws_batch = _module
aws_batch_runner = _module
aws_s3 = _module
s3_file_system = _module
class_config = _module
semantic_segmentation_label_store = _module
semantic_segmentation_label_store_config = _module
data_sample = _module
rv_pipeline = _module
rv_pipeline_config = _module
cog = _module
stac = _module
examples = _module
configs = _module
test_pipeline = _module
deluxe_message_maker = _module
my_config = _module
pipeline = _module
spacenet_viz = _module
sample_pipeline = _module
sample_pipeline2 = _module
tiny_spacenet = _module
gdal_vsi = _module
vsi_file_system = _module
file_system = _module
http_file_system = _module
local_file_system = _module
pipeline_config = _module
inprocess_runner = _module
local_runner = _module
pytorch_backend = _module
pytorch_learner_backend = _module
pytorch_learner_backend_config = _module
pytorch_learner = _module
classification_learner = _module
classification_learner_config = _module
classification = _module
regression = _module
image_folder = _module
learner = _module
learner_config = _module
learner_pipeline = _module
learner_pipeline_config = _module
object_detection_learner = _module
object_detection_learner_config = _module
object_detection_utils = _module
regression_learner = _module
regression_learner_config = _module
semantic_segmentation_learner = _module
semantic_segmentation_learner_config = _module
setup = _module
tests = _module
test_keras_classification_config = _module
test_pytorch_chip_classification = _module
test_pytorch_semantic_segmentation = _module
test_tf_deeplab_config = _module
test_tf_object_detection_config = _module
test_metrics = _module
test_cogify_command = _module
test_analyze_command = _module
test_aux_command = _module
test_bundle_command = _module
test_chip_command = _module
test_eval_command = _module
test_predict_command = _module
test_train_command = _module
test_box = _module
test_class_map = _module
test_command_io_definition = _module
test_config = _module
test_stats_analyzer = _module
noop_backend = _module
noop_command = _module
noop_evaluator = _module
noop_filesystem = _module
noop_label_source = _module
noop_label_store = _module
noop_raster_source = _module
noop_raster_transformer = _module
noop_runner = _module
noop_task = _module
noop_utils = _module
test_chip_classification_labels = _module
test_object_detection_labels = _module
test_semantic_segmentation_labels = _module
test_chip_classification_label_source = _module
test_object_detection_label_source = _module
test_segmentation_class_transformer = _module
test_semantic_segmentation_label_source = _module
test_chip_classification_geojson_store = _module
test_object_detection_geojson_store = _module
mock_crs_transformer = _module
test_rasterio_source = _module
test_rasterized_source = _module
test_raster_transformer = _module
test_activate_mixin = _module
test_scene = _module
test_geojson_vector_source = _module
test_vector_tile_vector_source = _module
test_chip_classification_evaluation = _module
test_chip_classification_evaluator = _module
test_class_evaluation_item = _module
test_classification_evaluator = _module
test_object_detection_evaluation = _module
test_semantic_segmentation_evaluation = _module
test_semantic_segmentation_evaluator = _module
test_experiment_config = _module
test_experiment_loader = _module
mock = _module
test_mocks = _module
test_aws_batch_experiment_runner = _module
test_chip_classification = _module
test_chip_classification_config = _module
test_object_detection_config = _module
test_semantic_segmentation_config = _module
test_plugin = _module
test_plugin_2 = _module
test_rv_config = _module
test_files = _module
test_misc = _module
test_zxy2geotiff = _module
tests_v2 = _module
mock_raster_source = _module
test_file_system = _module
test_utils = _module

from _paritybench_helpers import _mock_config, patch_functional
from unittest.mock import mock_open, MagicMock
from torch.autograd import Function
from torch.nn import Module
import re, math, string, numpy, torch, torchtext, torchaudio, logging, itertools, numbers, inspect, functools, copy, scipy, types, time, torchvision, enum, random, typing, warnings, abc, collections, uuid
import numpy as np
patch_functional()
open = mock_open()
logging = sys = argparse = MagicMock()
ArgumentParser = argparse.ArgumentParser
_global_config = args = argv = cfg = config = params = _mock_config()
argparse.ArgumentParser.return_value.parse_args.return_value = _global_config
sys.argv = _global_config
__version__ = '1.0.0'


import uuid


import logging


import time


import torch


from torch import optim


from torch.utils.tensorboard import SummaryWriter


from torch.optim.lr_scheduler import CyclicLR


import numpy as np


from collections import defaultdict


import random


from torch.utils.data import Dataset


from torch.utils.data import DataLoader


import torch.nn.functional as F


import torchvision


import torch.nn as nn


from torchvision.models.detection.faster_rcnn import FasterRCNN


from torchvision.models.detection.backbone_utils import BackboneWithFPN


from torchvision.models import resnet


from torchvision.ops import misc as misc_nn_ops


import warnings


from torchvision import models


from torch.utils.data import ConcatDataset


from abc import ABC


from abc import abstractmethod


import math


import numbers


from typing import Optional


from typing import List


from typing import Tuple


from typing import Dict


from typing import Union


from torch import Tensor


import torch.optim as optim


from torch.optim.lr_scheduler import MultiStepLR


from torch.optim.lr_scheduler import _LRScheduler


from torch.utils.data import Subset


from torchvision.ops.boxes import batched_nms


class BoxList:

    def __init__(self, boxes, **extras):
        """Constructor.

        Args:
            boxes: tensor<n, 4> with order ymin, xmin, ymax, xmax in pixels coords
            extras: dict with values that are tensors with first dimension corresponding
                to boxes first dimension
        """
        self.boxes = boxes
        self.extras = extras

    def get_field(self, name):
        if name == 'boxes':
            return self.boxes
        else:
            return self.extras.get(name)

    def _map_extras(self, func):
        new_extras = {}
        for k, v in self.extras.items():
            new_extras[k] = func(v)
        return new_extras

    def copy(self):
        return BoxList(self.boxes.copy(), **self._map_extras(lambda x: x.
            copy()))

    def cpu(self):
        return BoxList(self.boxes.cpu(), **self._map_extras(lambda x: x.cpu()))

    def cuda(self):
        return BoxList(self.boxes.cuda(), **self._map_extras(lambda x: x.
            cuda()))

    def to(self, device):
        return self.cpu() if device == 'cpu' else self.cuda()

    def xyxy(self):
        boxes = self.boxes[:, ([1, 0, 3, 2])]
        return BoxList(boxes, **self.extras)

    def yxyx(self):
        boxes = self.boxes[:, ([1, 0, 3, 2])]
        return BoxList(boxes, **self.extras)

    def __len__(self):
        return self.boxes.shape[0]

    @staticmethod
    def cat(box_lists):
        boxes = []
        extras = defaultdict(list)
        for bl in box_lists:
            boxes.append(bl.boxes)
            for k, v in bl.extras.items():
                extras[k].append(v)
        boxes = torch.cat(boxes)
        for k, v in extras.items():
            extras[k] = torch.cat(v)
        return BoxList(boxes, **extras)

    def equal(self, other):
        if len(other) != len(self):
            return False
        extras = [(v.float().unsqueeze(1) if v.ndim == 1 else v.float()) for
            v in self.extras.values()]
        cat_arr = torch.cat([self.boxes] + extras, 1)
        self_tups = set([tuple([x.item() for x in row]) for row in cat_arr])
        extras = [(v.float().unsqueeze(1) if v.ndim == 1 else v.float()) for
            v in other.extras.values()]
        cat_arr = torch.cat([other.boxes] + extras, 1)
        other_tups = set([tuple([x.item() for x in row]) for row in cat_arr])
        return self_tups == other_tups

    def ind_filter(self, inds):
        new_extras = {}
        for k, v in self.extras.items():
            new_extras[k] = v[inds, ...]
        return BoxList(self.boxes[(inds), :], **new_extras)

    def score_filter(self, score_thresh=0.25):
        scores = self.extras.get('scores')
        if scores is not None:
            return self.ind_filter(scores > score_thresh)
        else:
            raise ValueError('must have scores as key in extras')

    def clamp(self, img_height, img_width):
        boxes = torch.stack([torch.clamp(self.boxes[:, (0)], 0, img_height),
            torch.clamp(self.boxes[:, (1)], 0, img_width), torch.clamp(self
            .boxes[:, (2)], 0, img_height), torch.clamp(self.boxes[:, (3)],
            0, img_width)], dim=1)
        return BoxList(boxes, **self.extras)

    def nms(self, iou_thresh=0.5):
        if len(self) == 0:
            return self
        good_inds = batched_nms(self.boxes, self.get_field('scores'), self.
            get_field('class_ids'), iou_thresh)
        return self.ind_filter(good_inds)

    def scale(self, yscale, xscale):
        boxes = self.boxes * torch.tensor([[yscale, xscale, yscale, xscale]
            ], device=self.boxes.device)
        return BoxList(boxes, **self.extras)

    def pin_memory(self):
        self.boxes = self.boxes.pin_memory()
        for k, v in self.extras.items():
            self.extras[k] = v.pin_memory()
        return self


def get_out_channels(model):
    out = {}

    def make_save_output(layer_name):

        def save_output(layer, input, output):
            out[layer_name] = output.shape[1]
        return save_output
    model.layer1.register_forward_hook(make_save_output('layer1'))
    model.layer2.register_forward_hook(make_save_output('layer2'))
    model.layer3.register_forward_hook(make_save_output('layer3'))
    model.layer4.register_forward_hook(make_save_output('layer4'))
    model(torch.empty((1, 3, 128, 128)))
    return [out['layer1'], out['layer2'], out['layer3'], out['layer4']]


def resnet_fpn_backbone(backbone_name, pretrained):
    backbone = resnet.__dict__[backbone_name](pretrained=pretrained,
        norm_layer=misc_nn_ops.FrozenBatchNorm2d)
    for name, parameter in backbone.named_parameters():
        if ('layer2' not in name and 'layer3' not in name and 'layer4' not in
            name):
            parameter.requires_grad_(False)
    return_layers = {'layer1': 0, 'layer2': 1, 'layer3': 2, 'layer4': 3}
    out_channels = 256
    in_channels_list = get_out_channels(backbone)
    return BackboneWithFPN(backbone, return_layers, in_channels_list,
        out_channels)


class MyFasterRCNN(nn.Module):
    """Adapter around torchvision Faster-RCNN.

    The purpose of the adapter is to use a different input and output format
    and inject bogus boxes to circumvent torchvision's inability to handle
    training examples with no ground truth boxes.
    """

    def __init__(self, backbone_arch, num_labels, img_sz, pretrained=True):
        super().__init__()
        backbone = resnet_fpn_backbone(backbone_arch, pretrained)
        self.model = FasterRCNN(backbone, num_labels, min_size=img_sz,
            max_size=img_sz)
        self.subloss_names = ['total_loss', 'loss_box_reg',
            'loss_classifier', 'loss_objectness', 'loss_rpn_box_reg']

    def forward(self, input, targets=None):
        """Forward pass

        Args:
            input: tensor<n, 3, h, w> with batch of images
            targets: None or list<BoxList> of length n with boxes and labels

        Returns:
            if targets is None, returns list<BoxList> of length n, containing
            boxes, labels, and scores for boxes with score > 0.05. Further
            filtering based on score should be done before considering the
            prediction "final".

            if targets is a list, returns the losses as dict with keys from
            self.subloss_names.
        """
        if targets:
            new_targets = []
            for x, y in zip(input, targets):
                h, w = x.shape[1:]
                boxes = torch.cat([y.boxes, torch.tensor([[0.0, 0, h, w]],
                    device=input.device)], dim=0)
                labels = torch.cat([y.get_field('labels'), torch.tensor([0],
                    device=input.device)], dim=0)
                bl = BoxList(boxes, labels=labels)
                new_targets.append(bl)
            targets = new_targets
            _targets = [bl.xyxy() for bl in targets]
            _targets = [{'boxes': bl.boxes, 'labels': bl.get_field('labels'
                )} for bl in _targets]
            loss_dict = self.model(input, _targets)
            loss_dict['total_loss'] = sum(list(loss_dict.values()))
            return loss_dict
        out = self.model(input)
        boxlists = [BoxList(_out['boxes'], labels=_out['labels'], scores=
            _out['scores']).yxyx() for _out in out]
        new_boxlists = []
        for bl in boxlists:
            labels = bl.get_field('labels')
            non_zero_inds = labels != 0
            new_boxlists.append(bl.ind_filter(non_zero_inds))
        return new_boxlists


class MyFasterRCNN(nn.Module):
    """Adapter around torchvision Faster-RCNN.

    The purpose of the adapter is to use a different input and output format
    and inject bogus boxes to circumvent torchvision's inability to handle
    training examples with no ground truth boxes.
    """

    def __init__(self, backbone_arch, num_class_ids, img_sz, pretrained=True):
        super().__init__()
        backbone = resnet_fpn_backbone(backbone_arch, pretrained)
        self.null_class_id = num_class_ids
        self.model = FasterRCNN(backbone, num_class_ids + 2, min_size=
            img_sz, max_size=img_sz)
        self.subloss_names = ['total_loss', 'loss_box_reg',
            'loss_classifier', 'loss_objectness', 'loss_rpn_box_reg']
        self.batch_ind = 0

    def forward(self, input, targets=None):
        """Forward pass

        Args:
            input: tensor<n, 3, h, w> with batch of images
            targets: None or list<BoxList> of length n with boxes and class_ids

        Returns:
            if targets is None, returns list<BoxList> of length n, containing
            boxes, class_ids, and scores for boxes with score > 0.05. Further
            filtering based on score should be done before considering the
            prediction "final".

            if targets is a list, returns the losses as dict with keys from
            self.subloss_names.
        """
        if targets:
            new_targets = []
            for x, y in zip(input, targets):
                h, w = x.shape[1:]
                boxes = torch.cat([y.boxes, torch.tensor([[0.0, 0, h, w]],
                    device=input.device)], dim=0)
                class_ids = torch.cat([y.get_field('class_ids') + 1, torch.
                    tensor([self.null_class_id + 1], device=input.device)],
                    dim=0)
                bl = BoxList(boxes, class_ids=class_ids)
                new_targets.append(bl)
            targets = new_targets
            _targets = [bl.xyxy() for bl in targets]
            _targets = [{'boxes': bl.boxes, 'labels': bl.get_field(
                'class_ids')} for bl in _targets]
            loss_dict = self.model(input, _targets)
            loss_dict['total_loss'] = sum(list(loss_dict.values()))
            return loss_dict
        out = self.model(input)
        boxlists = [BoxList(_out['boxes'], class_ids=_out['labels'], scores
            =_out['scores']).yxyx() for _out in out]
        new_boxlists = []
        for bl in boxlists:
            class_ids = bl.get_field('class_ids') - 1
            non_null_inds = class_ids != self.null_class_id
            bl = bl.ind_filter(non_null_inds)
            bl.extras['class_ids'] -= 1
            new_boxlists.append(bl)
        return new_boxlists


class RegressionModel(nn.Module):

    def __init__(self, backbone_arch, out_features, pretrained=True,
        pos_out_inds=None):
        super().__init__()
        self.backbone = getattr(models, backbone_arch)(pretrained=pretrained)
        in_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Linear(in_features, out_features)
        self.pos_out_inds = pos_out_inds

    def forward(self, x):
        out = self.backbone(x)
        if self.pos_out_inds:
            for ind in self.pos_out_inds:
                out[:, (ind)] = out[:, (ind)].exp()
        return out


import torch
from torch.nn import MSELoss, ReLU
from _paritybench_helpers import _mock_config, _mock_layer, _paritybench_base, _fails_compile

class Test_azavea_raster_vision(_paritybench_base):
    pass
