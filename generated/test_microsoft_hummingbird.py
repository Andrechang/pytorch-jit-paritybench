import sys
_module = sys.modules[__name__]
del sys
hummingbird = _module
ml = _module
_container = _module
_parse = _module
_utils = _module
convert = _module
exceptions = _module
operator_converters = _module
_gbdt_commons = _module
_tree_commons = _module
_tree_implementations = _module
constants = _module
decision_tree = _module
gbdt = _module
lightgbm = _module
xgb = _module
supported = _module
setup = _module
test_backends = _module
test_lightgbm_converters = _module
test_no_extra_install = _module
test_sklearn_decision_tree_converters = _module
test_sklearn_gbdt_converters = _module
test_sklearn_histgbdt_converters = _module
test_xgboost_converters = _module
tree_utils = _module

from _paritybench_helpers import _mock_config
from unittest.mock import mock_open, MagicMock
from torch.autograd import Function
from torch.nn import Module
open = mock_open()
logging = sys = argparse = MagicMock()
ArgumentParser = argparse.ArgumentParser
_global_config = args = argv = cfg = config = params = _mock_config()
argparse.ArgumentParser.return_value.parse_args.return_value = _global_config
sys.argv = _global_config
__version__ = '1.0.0'


import numpy as np


import torch


from enum import Enum


from abc import ABC


from abc import abstractmethod


class PyTorchBackendModel(torch.nn.Module):
    """
    Container for a model compiled into PyTorch.
    """

    def __init__(self, input_names, output_names, operator_map, topology,
        extra_config):
        """
        Args:
            input_names: The names of the input `onnxconverter_common.topology.Variable`s for this model
            output_names: The names of the output `onnxconverter_common.topology.Variable`s generated by this model
            operator_map: A dictionary of operator aliases and related PyTorch implementations
            topology: A `onnxconverter_common.topology.Topology` object representing the model graph
            extra_config: Some additional custom configuration parameter
        """
        super(PyTorchBackendModel, self).__init__()
        self.input_names = input_names
        self.output_names = output_names
        self.operator_map = torch.nn.ModuleDict(operator_map)
        self.operators = list(topology.topological_operator_iterator())
        self.extra_config = extra_config
        self.is_regression = self.operator_map[self.operators[-1].full_name
            ].regression

    def forward(self, *inputs):
        with torch.no_grad():
            inputs = [*inputs]
            variable_map = {}
            device = next(self.parameters()).device
            for i, input_name in enumerate(self.input_names):
                if type(inputs[i]) is np.ndarray:
                    inputs[i] = torch.from_numpy(inputs[i])
                elif type(inputs[i]) is not torch.Tensor:
                    raise RuntimeError(
                        'Inputer tensor {} of not supported type {}'.format
                        (input_name, type(inputs[i])))
                if device is not None:
                    inputs[i] = inputs[i]
                variable_map[input_name] = inputs[i]
            for operator in self.operators:
                pytorch_op = self.operator_map[operator.full_name]
                pytorch_outputs = pytorch_op(*(variable_map[input] for
                    input in operator.input_full_names))
                if len(operator.output_full_names) == 1:
                    variable_map[operator.output_full_names[0]
                        ] = pytorch_outputs
                else:
                    for i, output in enumerate(operator.output_full_names):
                        variable_map[output] = pytorch_outputs[i]
            if len(self.output_names) == 1:
                return variable_map[self.output_names[0]]
            else:
                return list(variable_map[output_name] for output_name in
                    self.output_names)

    def predict(self, *inputs):
        """
        Utility functions used to emulate the behavior of the Sklearn API.
        On regression returns the predicted values.
        On classification tasks returns the predicted class labels for the input data.
        """
        if self.is_regression:
            return self.forward(*inputs).cpu().numpy().flatten()
        else:
            return self.forward(*inputs)[0].cpu().numpy()

    def predict_proba(self, *inputs):
        """
        Utility functions used to emulate the behavior of the Sklearn API.
        On regression a call to this method returns a `RuntimeError`.
        On classification tasks returns the probability estimates.
        """
        if self.is_regression:
            raise RuntimeError(
                'Predict_proba not available for regression tasks.')
        else:
            return self.forward(*inputs)[1].cpu().numpy()


class AbstracTreeImpl(ABC):
    """
    Abstract class definig the basic structure for tree-base models.
    """

    def __init__(self):
        super().__init__()

    @abstractmethod
    def aggregation(self, x):
        """
        Method defining the aggregation operation to execute after the model is evaluated.

        Args:
            x: An input tensor

        Returns:
            The tensor result of the aggregation
        """
        pass

    @abstractmethod
    def calibration(self, x):
        """
        Method implementating the calibration operation for classifiers.

        Args:
            x: An input tensor

        Returns:
            The tensor result of the calibration
        """
        pass


class AbstractPyTorchTreeImpl(AbstracTreeImpl, torch.nn.Module):
    """
    Abstract class definig the basic structure for tree-base models implemented in PyTorch.
    """

    def __init__(self, net_parameters, n_features, classes, n_classes):
        """
        Args:
            net_parameters: The parameters defining the tree structure
            n_features: The number of features input to the model
            classes: The classes used for classification. None if implementing a regression model
            n_classes: The total number of used classes
        """
        super(AbstractPyTorchTreeImpl, self).__init__()
        self.perform_class_select = False
        self.binary_classification = False
        self.classes = classes
        self.learning_rate = None
        self.regression = False
        self.alpha = None
        if classes is None:
            self.regression = True
            self.n_classes = 1
        else:
            self.n_classes = len(classes) if n_classes is None else n_classes
            if min(classes) != 0 or max(classes) != len(classes) - 1:
                self.classes = torch.nn.Parameter(torch.IntTensor(classes),
                    requires_grad=False)
                self.perform_class_select = True


import torch
from _paritybench_helpers import _mock_config, _mock_layer, _paritybench_base, _fails_compile

class Test_microsoft_hummingbird(_paritybench_base):
    pass
