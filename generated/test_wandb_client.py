import sys
_module = sys.modules[__name__]
del sys
conftest = _module
generate = _module
google_parser = _module
edgeml_tests = _module
test_fastai = _module
test_pytorch = _module
test_tensorflow2 = _module
test_tensorflow_keras = _module
setup = _module
all_media_types = _module
artifact_references = _module
artifact_storage = _module
big_file = _module
file_stream_long_line = _module
flapping_sweep = _module
get_sweep_runs = _module
image_bounding_box = _module
image_masks = _module
keras_tensorboard = _module
logging_granuarity_test = _module
mixed_keras = _module
mnist_with_summary = _module
molecule = _module
object3D = _module
performance = _module
point_cloud = _module
pytorch_tensorboard = _module
pytorch_tensorboardX = _module
simple = _module
simple_sweep = _module
simpsons_data_frames = _module
sparse_tensors = _module
sweep_check = _module
tensorboardX_video = _module
tensorflow2_tensorboard = _module
test_point_cloud_scene = _module
upload_simpsons_images = _module
tests = _module
api_mocks = _module
train = _module
mock_server = _module
test_artifacts = _module
test_catboost = _module
test_cli = _module
test_config = _module
test_data_types = _module
test_docker = _module
test_git_repo = _module
test_gym = _module
test_headless = _module
test_history = _module
test_internal_api = _module
test_keras = _module
test_lightgbm = _module
test_meta = _module
test_plots = _module
test_public_api = _module
test_ray = _module
test_retry = _module
test_run_manager = _module
test_settings = _module
test_sklearn = _module
test_summary = _module
test_system_stats = _module
test_tensorboard = _module
test_tensorflow = _module
test_torch = _module
test_util = _module
test_wandb = _module
test_wandb_run = _module
test_xgboost = _module
utils = _module
wandb = _module
apis = _module
file_stream = _module
internal = _module
public = _module
artifacts = _module
artifacts_cache = _module
catboost = _module
cli = _module
compat = _module
tempfile = _module
weakref = _module
windows = _module
core = _module
data_types = _module
dataframes = _module
docker = _module
auth = _module
www_authenticate = _module
env = _module
fastai = _module
file_pusher = _module
filesync = _module
stats = _module
step_checksum = _module
step_prepare = _module
step_upload = _module
upload_job = _module
git_repo = _module
gym = _module
history = _module
internal_cli = _module
io_wrap = _module
jsonlfile = _module
jupyter = _module
keras = _module
kubeflow = _module
arena = _module
lightgbm = _module
magic = _module
magic_impl = _module
meta = _module
plots = _module
explain_text = _module
heatmap = _module
named_entity = _module
part_of_speech = _module
plot_definitions = _module
precision_recall = _module
roc = _module
ray = _module
retry = _module
run_manager = _module
settings = _module
sklearn = _module
sparkline = _module
streaming_log = _module
summary = _module
sweeps = _module
base = _module
bayes_search = _module
config = _module
cfg = _module
hyperopt = _module
hp = _module
tune = _module
schedulers = _module
async_hyperband = _module
engine = _module
envelope_stopping = _module
grid_search = _module
hyperband_stopping = _module
params = _module
random_search = _module
raytune = _module
test_bayes_search = _module
test_envelope_stopping = _module
test_grid_search = _module
test_hyperband_stopping = _module
test_random_search = _module
util = _module
tensorboard = _module
watcher = _module
tensorflow = _module
trigger = _module
typedtable = _module
util = _module
prompt_toolkit = _module
application = _module
auto_suggest = _module
buffer = _module
buffer_mapping = _module
cache = _module
clipboard = _module
in_memory = _module
pyperclip = _module
completion = _module
contrib = _module
completers = _module
filesystem = _module
system = _module
regular_languages = _module
compiler = _module
lexer = _module
regex_parser = _module
validation = _module
telnet = _module
log = _module
protocol = _module
server = _module
validators = _module
document = _module
enums = _module
eventloop = _module
asyncio_base = _module
asyncio_posix = _module
asyncio_win32 = _module
callbacks = _module
inputhook = _module
posix = _module
posix_utils = _module
select = _module
win32 = _module
filters = _module
types = _module
input = _module
interface = _module
key_binding = _module
bindings = _module
basic = _module
emacs = _module
named_commands = _module
scroll = _module
vi = _module
defaults = _module
digraphs = _module
input_processor = _module
manager = _module
registry = _module
vi_state = _module
keys = _module
layout = _module
containers = _module
controls = _module
dimension = _module
lexers = _module
margins = _module
menus = _module
mouse_handlers = _module
processors = _module
prompt = _module
screen = _module
toolbars = _module
mouse_events = _module
output = _module
reactive = _module
renderer = _module
search_state = _module
selection = _module
shortcuts = _module
styles = _module
from_dict = _module
from_pygments = _module
terminal = _module
conemu_output = _module
vt100_input = _module
vt100_output = _module
win32_input = _module
win32_output = _module
token = _module
win32_types = _module
pygments = _module
cmdline = _module
console = _module
filter = _module
formatter = _module
formatters = _module
_mapping = _module
bbcode = _module
html = _module
img = _module
irc = _module
latex = _module
other = _module
rtf = _module
svg = _module
terminal256 = _module
_asy_builtins = _module
_cl_builtins = _module
_cocoa_builtins = _module
_csound_builtins = _module
_lasso_builtins = _module
_lua_builtins = _module
_mql_builtins = _module
_openedge_builtins = _module
_php_builtins = _module
_postgres_builtins = _module
_scilab_builtins = _module
_sourcemod_builtins = _module
_stan_builtins = _module
_stata_builtins = _module
_tsql_builtins = _module
_vim_builtins = _module
actionscript = _module
agile = _module
algebra = _module
ambient = _module
ampl = _module
apl = _module
archetype = _module
asm = _module
automation = _module
bibtex = _module
business = _module
c_cpp = _module
c_like = _module
capnproto = _module
chapel = _module
clean = _module
compiled = _module
configs = _module
crystal = _module
csound = _module
css = _module
d = _module
dalvik = _module
data = _module
diff = _module
dotnet = _module
dsls = _module
dylan = _module
ecl = _module
eiffel = _module
elm = _module
erlang = _module
esoteric = _module
ezhil = _module
factor = _module
fantom = _module
felix = _module
forth = _module
fortran = _module
foxpro = _module
functional = _module
go = _module
grammar_notation = _module
graph = _module
graphics = _module
haskell = _module
haxe = _module
hdl = _module
hexdump = _module
idl = _module
igor = _module
inferno = _module
installers = _module
int_fiction = _module
iolang = _module
j = _module
javascript = _module
julia = _module
jvm = _module
lisp = _module
make = _module
markup = _module
math = _module
matlab = _module
ml = _module
modeling = _module
modula2 = _module
monte = _module
ncl = _module
nimrod = _module
nit = _module
nix = _module
oberon = _module
objective = _module
ooc = _module
parasail = _module
parsers = _module
pascal = _module
pawn = _module
perl = _module
php = _module
praat = _module
prolog = _module
python = _module
qvt = _module
r = _module
rdf = _module
rebol = _module
resource = _module
rnc = _module
roboconf = _module
robotframework = _module
ruby = _module
rust = _module
sas = _module
scripting = _module
shell = _module
smalltalk = _module
smv = _module
snobol = _module
special = _module
sql = _module
stata = _module
supercollider = _module
tcl = _module
templates = _module
testing = _module
text = _module
textedit = _module
textfmts = _module
theorem = _module
trafficscript = _module
typoscript = _module
urbi = _module
varnish = _module
verification = _module
web = _module
webmisc = _module
whiley = _module
x10 = _module
modeline = _module
plugin = _module
regexopt = _module
scanner = _module
sphinxext = _module
style = _module
abap = _module
algol = _module
algol_nu = _module
arduino = _module
autumn = _module
borland = _module
bw = _module
colorful = _module
default = _module
friendly = _module
fruity = _module
lovelace = _module
manni = _module
monokai = _module
murphy = _module
native = _module
paraiso_dark = _module
paraiso_light = _module
pastie = _module
perldoc = _module
rainbow_dash = _module
rrt = _module
tango = _module
trac = _module
vim = _module
vs = _module
xcode = _module
unistring = _module
wcwidth = _module
table_wide = _module
table_zero = _module
test_core = _module
whaaaaat = _module
color_print = _module
prompts = _module
checkbox = _module
common = _module
confirm = _module
expand = _module
list = _module
password = _module
rawlist = _module
separator = _module
viz = _module
wandb_agent = _module
wandb_config = _module
wandb_controller = _module
wandb_keras = _module
wandb_run = _module
wandb_socket = _module
wandb_torch = _module
wandb_types = _module
xgboost = _module

from _paritybench_helpers import _mock_config, patch_functional
from unittest.mock import mock_open, MagicMock
from torch.autograd import Function
from torch.nn import Module
import abc, collections, copy, enum, functools, inspect, itertools, logging, math, numbers, numpy, random, re, scipy, sklearn, string, tensorflow, time, torch, torchaudio, torchtext, torchvision, types, typing, uuid, warnings
import numpy as np
from torch import Tensor
patch_functional()
open = mock_open()
yaml = logging = sys = argparse = MagicMock()
ArgumentParser = argparse.ArgumentParser
_global_config = args = argv = cfg = config = params = _mock_config()
argparse.ArgumentParser.return_value.parse_args.return_value = _global_config
yaml.load.return_value = _global_config
sys.argv = _global_config
__version__ = '1.0.0'


import torch


import logging


import torch.nn as nn


import torch.nn.functional as F


from torch.utils.tensorboard import SummaryWriter


import numpy


import tensorflow


from torchvision import models


import torch.optim as optim


import numpy as np


import tensorflow as tf


import time


from torch.autograd import Variable


import random


import re


import collections


import copy


import numbers


import types


from collections import namedtuple


from collections import Mapping


from collections import Sequence


from collections import OrderedDict


import inspect


import itertools


class ConvNet(nn.Module):

    def __init__(self):
        super(ConvNet, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)


class NGramLanguageModeler(nn.Module):

    def __init__(self, vocab_size, embedding_dim, context_size):
        super(NGramLanguageModeler, self).__init__()
        self.embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)
        self.linear1 = nn.Linear(context_size * embedding_dim, 128)
        self.linear2 = nn.Linear(128, vocab_size)

    def forward(self, inputs):
        embeds = self.embeddings(inputs).view((1, -1))
        out = F.relu(self.linear1(embeds))
        out = self.linear2(out)
        log_probs = F.log_softmax(out, dim=1)
        return log_probs


class DynamicModule(nn.Module):

    def __init__(self):
        super(DynamicModule, self).__init__()
        self.choices = nn.ModuleDict({'conv': nn.Conv2d(10, 10, 3), 'pool': nn.MaxPool2d(3)})
        self.activations = nn.ModuleDict([['lrelu', nn.LeakyReLU()], ['prelu', nn.PReLU()]])

    def forward(self, x, choice, act):
        x = self.choices[choice](x)
        x = self.activations[act](x)
        return x


class Discrete(nn.Module):

    def __init__(self):
        super(Discrete, self).__init__()

    def forward(self, x):
        return nn.functional.softmax(x, dim=0)


class DiscreteModel(nn.Module):

    def __init__(self, num_outputs=2):
        super(DiscreteModel, self).__init__()
        self.linear1 = nn.Linear(1, 10)
        self.linear2 = nn.Linear(10, num_outputs)
        self.dist = Discrete()

    def forward(self, x):
        x = self.linear1(x)
        x = self.linear2(x)
        return self.dist(x)


class ParameterModule(nn.Module):

    def __init__(self):
        super(ParameterModule, self).__init__()
        self.params = nn.ParameterList([nn.Parameter(torch.ones(10, 10)) for i in range(10)])
        self.otherparam = nn.Parameter(torch.Tensor(5))

    def forward(self, x):
        for i, p in enumerate(self.params):
            x = self.params[i // 2].mm(x) + p.mm(x)
        return x


def init_conv_weights(layer, weights_std=0.01, bias=0):
    """Initialize weights for subnet convolution"""
    if parse_version(torch.__version__) >= parse_version('0.4'):
        nn.init.normal_(layer.weight.data, std=weights_std)
        nn.init.constant_(layer.bias.data, val=bias)
    else:
        nn.init.normal(layer.weight.data, std=weights_std)
        nn.init.constant(layer.bias.data, val=bias)
    return layer


def conv3x3(in_channels, out_channels, **kwargs):
    """Return a 3x3 convolutional layer for SubNet"""
    layer = nn.Conv2d(in_channels, out_channels, kernel_size=3, **kwargs)
    layer = init_conv_weights(layer)
    return layer


class SubNet(nn.Module):

    def __init__(self, mode, anchors=9, classes=80, depth=4, base_activation=F.relu, output_activation=F.sigmoid):
        super(SubNet, self).__init__()
        self.anchors = anchors
        self.classes = classes
        self.depth = depth
        self.base_activation = base_activation
        self.output_activation = output_activation
        self.subnet_base = nn.ModuleList([conv3x3(256, 256, padding=1) for _ in range(depth)])
        if mode == 'boxes':
            self.subnet_output = conv3x3(256, 4 * self.anchors, padding=1)
        elif mode == 'classes':
            self.subnet_output = conv3x3(256, (1 + self.classes) * self.anchors, padding=1)
        self._output_layer_init(self.subnet_output.bias.data)

    def _output_layer_init(self, tensor, pi=0.01):
        fill_constant = 4.59
        return tensor.fill_(fill_constant)

    def forward(self, x):
        for layer in self.subnet_base:
            x = self.base_activation(layer(x))
        x = self.subnet_output(x)
        x = x.permute(0, 2, 3, 1).contiguous().view(x.size(0), x.size(2) * x.size(3) * self.anchors, -1)
        return x


class LSTMModel(torch.nn.Module):

    def __init__(self, embedding_dim, hidden_dim):
        super(LSTMModel, self).__init__()
        vocabLimit = 100
        self.hidden_dim = hidden_dim
        self.embeddings = nn.Embedding(vocabLimit + 1, embedding_dim)
        self.lstm = nn.LSTM(embedding_dim, hidden_dim)
        self.linearOut = nn.Linear(hidden_dim, 2)

    def forward(self, inputs, hidden):
        x = self.embeddings(inputs).view(len(inputs), 1, -1)
        lstm_out, lstm_h = self.lstm(x, hidden)
        x = lstm_out[-1]
        x = self.linearOut(x)
        x = F.log_softmax(x, dim=1)
        return x, lstm_h

    def init_hidden(self):
        return Variable(torch.zeros(1, 1, self.hidden_dim)), Variable(torch.zeros(1, 1, self.hidden_dim))


def dummy_torch_tensor(size, requires_grad=True):
    if parse_version(torch.__version__) >= parse_version('0.4'):
        return torch.ones(size, requires_grad=requires_grad)
    else:
        return torch.autograd.Variable(torch.ones(size), requires_grad=requires_grad)


class Sequence(nn.Module):

    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future=0):
        outputs = []
        h_t = dummy_torch_tensor((input.size(0), 51))
        c_t = dummy_torch_tensor((input.size(0), 51))
        h_t2 = dummy_torch_tensor((input.size(0), 51))
        c_t2 = dummy_torch_tensor((input.size(0), 51))
        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs


class FCLayer(nn.Module):
    """FC Layer + Activation"""

    def __init__(self, dims, batchnorm_dim=0, act='ReLU', dropout=0):
        super(FCLayer, self).__init__()
        layers = []
        for i in range(len(dims) - 2):
            in_dim = dims[i]
            out_dim = dims[i + 1]
            if 0 < dropout:
                layers.append(nn.Dropout(dropout))
            None
            layers.append(nn.Linear(in_dim, out_dim))
            if '' != act:
                layers.append(getattr(nn, act)())
            if batchnorm_dim > 0:
                layers.append(nn.BatchNorm1d(batchnorm_dim))
        if 0 < dropout:
            layers.append(nn.Dropout(dropout))
        layers.append(nn.Linear(dims[-2], dims[-1]))
        if '' != act:
            layers.append(getattr(nn, act)())
        self.net = nn.Sequential(*layers)

    def forward(self, x):
        return self.net(x)


class VGGConcator(nn.Module):
    """
    Extracts feature of each four panels, concatenates 4 vgg features panel-wise.
    """

    def __init__(self):
        super(VGGConcator, self).__init__()
        self.vgg = models.vgg16(pretrained=False)
        self.vgg.classifier = nn.Sequential(*list(self.vgg.classifier.children())[:-1])

    def forward(self, panels, num=1):
        if num == 1:
            features = self.vgg(panels)
        else:
            img0 = panels[:, (0), :, :, :]
            img1 = panels[:, (1), :, :, :]
            img2 = panels[:, (2), :, :, :]
            img3 = panels[:, (3), :, :, :]
            feature0 = self.vgg(img0)
            feature1 = self.vgg(img1)
            feature2 = self.vgg(img2)
            feature3 = self.vgg(img3)
            features = torch.cat((feature0[:, (None), :], feature1[:, (None), :], feature2[:, (None), :], feature3[:, (None), :]), dim=1)
        return features


class Embedding(nn.Module):

    def __init__(self, d_embedding, d_word, d_hidden, word_dim, dropout, sparse=False):
        super(Embedding, self).__init__()
        glove = torch.ones((10, 300))
        self.vgg = VGGConcator()
        self.word_dim = word_dim
        glove = glove[:self.word_dim]
        self.d_word = d_word
        self.emb = nn.Embedding(word_dim, 300, padding_idx=0, sparse=sparse)
        self.emb.weight.data = glove
        self.d_img = 4096
        self.num_panels = 4
        self.num_max_sentences = 3
        self.num_max_words = 20
        self.img_fc0 = FCLayer([self.d_img, d_hidden], dropout=dropout)
        self.box_lstm = nn.LSTM(300, d_word, 1, batch_first=True, bidirectional=False)
        self.fc0 = FCLayer([d_word + d_hidden, d_embedding])

    def forward(self, images, words):
        words = words.long()
        batch_size = words.size(0)
        box_hidden = self.init_hidden(batch_size, self.d_word, 1, 4)
        words = words.view(-1, words.size(-1))
        emb_word = self.emb(words)
        None
        emb_word = emb_word.view(-1, self.num_panels, self.num_max_sentences, self.num_max_words, self.d_word)
        emb_sentence = torch.sum(emb_word, dim=3)
        emb_sentence = emb_sentence.view(-1, self.num_max_sentences, self.d_word)
        lstmed_sentence, _ = self.box_lstm(emb_sentence, box_hidden)
        emb_panel_sentence = lstmed_sentence[:, (-1), :]
        emb_panel_sentence = emb_panel_sentence.view(-1, self.num_panels, self.d_word)
        img_feature = self.vgg(images, num=4)
        img_feature = self.img_fc0(img_feature)
        fusion = torch.cat((img_feature, emb_panel_sentence), dim=-1)
        fusion = self.fc0(fusion)
        return fusion

    def init_hidden(self, batch, out, direction=1, n=1):
        dims = direction, batch * n, out
        hiddens = Variable(torch.zeros(*dims)), Variable(torch.zeros(*dims))
        return hiddens


import torch
from torch.nn import MSELoss, ReLU
from _paritybench_helpers import _mock_config, _mock_layer, _paritybench_base, _fails_compile


TESTCASES = [
    # (nn.Module, init_args, forward_args, jit_compiles)
    (Discrete,
     lambda: ([], {}),
     lambda: ([torch.rand([4, 4, 4, 4])], {}),
     True),
    (DiscreteModel,
     lambda: ([], {}),
     lambda: ([torch.rand([1, 1])], {}),
     True),
    (FCLayer,
     lambda: ([], {'dims': [4, 4]}),
     lambda: ([torch.rand([4, 4, 4, 4])], {}),
     True),
    (NGramLanguageModeler,
     lambda: ([], {'vocab_size': 4, 'embedding_dim': 4, 'context_size': 4}),
     lambda: ([torch.zeros([4], dtype=torch.int64)], {}),
     True),
    (ParameterModule,
     lambda: ([], {}),
     lambda: ([torch.rand([10, 10])], {}),
     False),
]

class Test_wandb_client(_paritybench_base):
    def test_000(self):
        self._check(*TESTCASES[0])

    def test_001(self):
        self._check(*TESTCASES[1])

    def test_002(self):
        self._check(*TESTCASES[2])

    def test_003(self):
        self._check(*TESTCASES[3])

    def test_004(self):
        self._check(*TESTCASES[4])

